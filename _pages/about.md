---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a PhD candidate advised by Prof. Philippe Langlais. My research spans efficient architectures for LLMs, LLM calibration and reliability, and Length Generalization.


# ğŸ”¥ News
- *2026.01*: &nbsp;ğŸ‰ğŸ‰ Two papers are accepted by WWW 2026 industry track.
- *2026.01*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by EACL 2026 (main).
- *2025.09*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by NeurIPS 2025.
- *2025.07*: &nbsp;ğŸ‰ğŸ‰ Two papers are accepted by ECAI 2025.
- *2025.07*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by COLM 2025. 
- *2025.05*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by ICML 2025.

# ğŸ“ Selected Publications 

- `NeurIPS 2025` [Mamba Modulation: On the Length Generalization of Mamba Models](https://openreview.net/forum?id=QEU047bE8p), **Peng LU**, Jerry Huang, QIUHAO Zeng, Xinyu Wang, Boxing Chen, Philippe Langlais, Yufei Cui

- `ICML 2025` [Calibrated Language Models and How to Find Them with Label Smoothing](https://openreview.net/forum?id=soLNj4l2EL), **Peng LU**, Jerry Huang, QIUHAO Zeng

- `COLM 2025` [Resona: Improving Context Copying in Linear Recurrence Models with Retrieval](https://openreview.net/forum?id=4mxQmpnawk), Xinyu Wang, Linrui Ma, Jerry Huang, **Peng Lu**, Prasanna Parthasarathi, Xiao-Wen Chang, Boxing Chen, Yufei Cui

- `ECAI 2025` [An Interpretable Quantum-Inspired Model for Multi-Task Natural Language Understanding](https://ebooks.iospress.nl/volumearticle/75874), **Peng Lu**, Jerry Huang, Xinyu Wang, Philippe Langlais

- `ECAI 2025` [PoT-PTQ: Two-Step Power-of-Two Post-Training for LLMs](https://ebooks.iospress.nl/volumearticle/76124), Xinyu Wang, Vahid Partovi Nia, **Peng Lu**, Jerry Huang, Xiao-Wen Chang, Boxing Chen, Yufei Cui
- `ICLR 2025` [ZETA: Leveraging Z-order Curves for Efficient Top-k Attention](https://openreview.net/forum?id=j9VVzueEbG), Qiuhao Zeng, Jerry Huang, **Peng Lu**, Gezheng Xu, Boxing Chen, Charles Ling, Boyu Wang

- `NAACL 2025` [ReGLA: Refining Gated Linear Attention](https://aclanthology.org/2025.naacl-long.147/), **Peng Lu**, Ivan Kobyzev, Mehdi Rezagholizadeh, Boxing Chen, Philippe Langlais
- `CIMK 2025 industry track` [FinSage: A Multi-aspect RAG System for Financial Filings Question Answering](https://dl.acm.org/doi/10.1145/3746252.3761587), Xinyu Wang, Jijun Chi, Zhenghan Tai, Tung Sum Thomas Kwok, Muzhi Li, Zhuhong Li, Hailin He, Yuchen Hua, **Peng Lu** et al.

- `EMNLP 2024 Findings` [Draft on the fly: Adaptive self-speculative decoding using cosine similarity](https://aclanthology.org/2024.findings-emnlp.124/), Michael R. Metel, **Peng Lu**, Boxing Chen, Mehdi Rezagholizadeh, and Ivan Kobyzev

- `ACL 2024 Findings` [Resonance RoPE: Improving context length generalization of large language models](https://aclanthology.org/2024.findings-acl.32/), Suyuchen Wang, Ivan Kobyzev, **Peng Lu**, Mehdi Rezagholizadeh, and Bang Liu

- `ACL 2023 Findings` [LABO:
Towards learning optimal label regularization via bi-level optimization](https://aclanthology.org/2023.findings-acl.356/), **Peng Lu**, Ahmad Rashid, Ivan Kobyzev, Mehdi Rezagholizadeh, and Phillippe Langlais

- `EMNLP 2023` [Efficient classification
of long documents via state-space models](https://aclanthology.org/2023.emnlp-main.404/), **Peng Lu**, Suyuchen Wang, Mehdi Rezagholizadeh, Bang Liu, and Ivan Kobyzev

- `EMNLP 2022 Findings` [Improving generalization of pre-trained language models via stochastic weight averaging](https://aclanthology.org/2022.findings-emnlp.363/), **Peng Lu**, Ivan Kobyzev, Mehdi Rezagholizadeh, Ahmad Rashid, Ali Ghodsi, and Phillippe Langlais
- `EMNLP 2021 Findings` [RW-KD: Sample-wise loss terms re-weighting for knowledge distillation](https://aclanthology.org/2021.findings-emnlp.270/), **Peng Lu**, Abbas Ghaddar, Ahmad Rashid, Mehdi Rezagholizadeh, Ali Ghodsi, and Philippe Langlais

- `NAACL 2019` [SC-LSTM: Learning task-specific representations in multi-task learning for sequence labeling](https://aclanthology.org/N19-1249/), **Peng Lu**, Ting Bai, and Philippe Langlais


# ğŸ’» Internships
- *2020.09 - 2025.12*, [Huawei Noahâ€™s Ark Lab
], Canada.
